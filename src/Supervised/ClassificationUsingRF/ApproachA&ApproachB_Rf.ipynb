{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Kumar Awanish,\n",
    "Content: Impementation of Binary Mode(Approach A) and Classifying Attacks(Approach B),\n",
    "Technology used: Python3,Spark(PySpark),tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import  StringIndexer, VectorAssembler, IndexToString\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.serializers import MarshalSerializer\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import when \n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Spark enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "memory = '20g'\n",
    "pyspark_submit_args = ' --driver-memory ' + memory + ' pyspark-shell'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = pyspark_submit_args\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '6g')\n",
    "#SparkContext.setSystemProperty('spark.driver.memory', '10g')\n",
    "sc = SparkContext('local','example')  # if using locally\n",
    "sql_sc = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_loading(dataset):\n",
    "    \"\"\"\n",
    "    This function will load dataset using Spark cluster.\n",
    "    :param dataset: dataset to load and process\n",
    "    :return: a Spark dataframe\n",
    "    \"\"\"\n",
    "    dataset=sql_sc.read.format('csv').options(header='true', inferSchema='true').load(dataset)\n",
    "    #changing column header name\n",
    "    dataset = dataset.select(*[col(s).alias('Label') if s == ' Label' else s for s in dataset.columns])\n",
    "    #to change datatype\n",
    "    dataset=dataset.drop('External IP')\n",
    "    dataset=dataset.filter(dataset.Label!=' Label')#filter Label from label\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation of Lables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "def data_plot(dataset):\n",
    "    \"\"\"\n",
    "    This function is to visualise numbers of labels and their respective records.\n",
    "    :param dataset: a spark dataframe\n",
    "    \"\"\"\n",
    "    label_counts=dataset.groupBy('Label').count().collect()\n",
    "    categories = [i[0] for i in label_counts[0:]]\n",
    "    counts = [i[1] for i in label_counts[0:]]\n",
    "    ind = np.array(range(len(categories)))\n",
    "    width = 0.55\n",
    "    # Set the figure size\n",
    "    fig = plt.figure(1, [40, 20])\n",
    "    plt.bar(ind, counts, width=width, color='r')\n",
    "    plt.ylabel('counts')\n",
    "    plt.title('Response distribution')\n",
    "    plt.xticks(ind + width/2., categories,fontsize=12)\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n",
    "    #plt.colors(color=[0,16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(dataset):\n",
    "    \"\"\"\n",
    "    This function is for preprocessing of datasets.\n",
    "    :param dataset: a spark dataframe\n",
    "    :return dataWithFeatures: a spark dataframe after preprocessing \n",
    "    \"\"\"\n",
    "    featureList=[' Flow Duration', ' Fwd IAT Min', ' Bwd IAT Mean', ' Fwd IAT Mean','Init_Win_bytes_forward',' Subflow Fwd Bytes','Total Length of Fwd Packets',\n",
    "      ' ACK Flag Count', ' Active Min', 'Active Mean',' Flow IAT Std','Init_Win_bytes_forward','Fwd PSH Flags',' SYN Flag Count',\n",
    "      'Fwd Packets/s',' Bwd Packet Length Std','Total Length of Fwd Packets','Init_Win_bytes_forward',' Init_Win_bytes_backward','Total Length of Fwd Packets',\n",
    "      'Total Length of Fwd Packets','Active Mean','Total Length of Fwd Packets',' Fwd Packet Length Mean',' Average Packet Size','Init_Win_bytes_forward', ' Bwd Packets/s', ' PSH Flag Count', ' Flow IAT Min', ' Fwd IAT Min', ' Flow IAT Mean']\n",
    "    uniqueFeature=list(set(featureList))\n",
    "    uniqueFeature.append('Label')\n",
    "    # attack labels to encode itno 0\n",
    "    labels=[\"DoS Slowhttptest\",'Web Attack � Brute Force','Web Attack � Sql Injection','Web Attack � XSS',\"SSH-Patator\",\"DoS GoldenEye\", \"Heartbleed\", \"DoS Hulk\", \"DoS slowloris\", \"FTP-Patator\", \"Infiltration\",\"Bot\",\"PortScan\",\"DDoS\"]\n",
    "    #change benign to 1 else 0\n",
    "    newDf = dataset.withColumn('Label',when(dataset.Label.isin(labels),0).otherwise(1))\n",
    "    #to change datatype\n",
    "    final_data=newDf.select(*(col(c).cast(\"float\").alias(c) for c in newDf.columns))\n",
    "    final_data = final_data.filter(final_data.Label.isNotNull())\n",
    "    final_data = final_data.na.fill(0.0)\n",
    "    print(final_data.groupBy('Label').count().collect())\n",
    "    #print(final_data.select('Label').show())\n",
    "    dataWithFeatures=final_data.select([c for c in final_data.columns if c in uniqueFeature])\n",
    "    #print(dataWithFeatures.columns)\n",
    "    return dataWithFeatures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampling(dataWithFeatures):\n",
    "    \"\"\"\n",
    "    This function is to sample dataset\n",
    "    :param dataWithFeatures: preprocessed spark dataframe\n",
    "    :return dataWithSampling: a samsple sparked dataframe\n",
    "    \"\"\"\n",
    "    dataWithSampling=dataWithFeatures.sampleBy('Label',fractions={0:1.0, 1: 471454./2647898})\n",
    "    #dataWithSamples.count()\n",
    "    print(dataWithSamples.groupBy('Label').count().collect())\n",
    "    return dataWithSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorAssembler(dataWithFeatures):\n",
    "    \"\"\"\n",
    "    This function is for creating feature indexer, which will be helpful in running RF model on PySpark Api.\n",
    "    :param dataWithFeatures: preprocessed spark dataframe\n",
    "    :return dataWithFeatures: spark dataframe with feature indexer column added to it\n",
    "    \"\"\"\n",
    "    stages = [] # stages in our Pipeline\n",
    "    assemblerInputs=dataWithFeatures.columns[0:-1]\n",
    "    assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features_new\")\n",
    "    #assembler.transform(final_data)\n",
    "    assembler.transform(dataWithFeatures.na.drop())\n",
    "    stages += [assembler]\n",
    "    cols = dataWithFeatures.columns\n",
    "    # Create a Pipeline.\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    # Run the feature transformations.\n",
    "    #  - fit() computes feature statistics as needed.\n",
    "    #  - transform() actually transforms the features.\n",
    "    pipelineModel = pipeline.fit(dataWithFeatures)\n",
    "    dataWithFeatures = pipelineModel.transform(dataWithFeatures)\n",
    "    # Keep relevant columns\n",
    "    selectedcols = [\"features_new\"] + cols\n",
    "    dataWithFeatures = dataWithFeatures.select(selectedcols)\n",
    "    return dataWithFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_data(dataWithFeatures):\n",
    "    \"\"\"\n",
    "    This function is to create test and train data by using randomSplit function from PySpark\n",
    "    :param dataWithFeatures: preprocessed spark dataframe\n",
    "    :return : trainingData,testData\n",
    "    \"\"\"\n",
    "    ###split data into training and test sets. set seed for reproducibility\n",
    "    (trainingData, testData) = dataWithFeatures.randomSplit([0.8, 0.2], seed=100)\n",
    "    #To get rows and columns=shape() in Pandas\n",
    "    print(\"Number of records for training: \" + str(trainingData.count()))\n",
    "    print(\"Number of records for evaluation: \" + str(testData.count()))\n",
    "    return trainingData,testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(train_data):\n",
    "    \"\"\"\n",
    "    This function is to train model on RF classifier\n",
    "    :param train_data: training data obtained from train_test_data method\n",
    "    :return rfModel: tarined model using RF classifier\n",
    "    \"\"\"\n",
    "    # Train a RandomForest model.This also runs the indexers.\n",
    "    rf = RandomForestClassifier(labelCol=\"Label\", featuresCol=\"features_new\", numTrees=200,maxDepth=25)  \n",
    "    t= time.time()\n",
    "    rfModel = rf.fit(train_data)\n",
    "    elapsed_time = time.time() - t\n",
    "    print(elapsed_time)\n",
    "    #save model\n",
    "    rfModel.save('BinaryModel')\n",
    "    return rfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def results(rfModel):\n",
    "    \"\"\"\n",
    "    This function will output model evaluations and its reuslts.\n",
    "    \"\"\"\n",
    "    # Make predictions.\n",
    "    y_predictionsRf = rfModel.transform(testData)\n",
    "    # Evaluate model\n",
    "    evaluatorRf = BinaryClassificationEvaluator(labelCol=\"Label\")\n",
    "    accuracyRf=evaluatorRf.evaluate(y_predictionsRf)\n",
    "    outputrf=np.array(y_predictionsRf.select('prediction').collect())\n",
    "    input_array=np.array(testData.select('Label').collect())\n",
    "    print(input_array.shape,outputrf.shape)\n",
    "    print(\"Accuracy of RandomForestClassifier = %g \" % (accuracyRf))\n",
    "    print (\"Test Error in RandomForestClassifier = %g \" % (1.0 - accuracyRf))\n",
    "    print(\"Precision Score for RF model=%g\"%(precision_score(input_array, outputrf, average='macro')))\n",
    "    print(\"Recall Score for RF model=%g\"%(recall_score(input_array, outputrf, average='macro') )) \n",
    "    print(\"F1 Score for RF model=%g\"%(f1_score(input_array, outputrf, average='macro')))\n",
    "    print(\"Benign vs Attack result classification_report\")\n",
    "    print(classification_report(input_array, outputrf,target_names=['Attack','Benign']))\n",
    "    return input_array,outputrf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data viusaltion using Tsne uisng Binary mode for test data using true and predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataXX=dataWithFeatures.toPandas()\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.manifold import TSNE\n",
    "#dataVisualisationBinaryMode=testData.toPandas()\n",
    "#dataVisualisationBinaryMode.drop(['features', ' SYN Flag Count', ' PSH Flag Count',' ACK Flag Count','Fwd PSH Flags'],axis=1,inplace=True)\n",
    "def tsneTrain(testData):\n",
    "    dataVisualisationBinaryMode=testData.toPandas()\n",
    "    dataVisualisationBinaryMode.drop(['features', ' SYN Flag Count', ' PSH Flag Count',' ACK Flag Count','Fwd PSH Flags'],axis=1,inplace=True)\n",
    "    time_start = time.time()\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=50,learning_rate=400.0,n_iter=1500)\n",
    "    tsne_resultsRf = tsne.fit_transform(dataVisualisationBinaryMode[:80000])\n",
    "    print ('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "    with open('tsneTrainResults.npy','wb') as fout:\n",
    "        pickle.dump(tsne_resultsRf,fout,pickle.DEFAULT_PROTOCOL)\n",
    "    return tsne_resultsRf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plot(tsne_resultsRfPred,labelss,str):\n",
    "    #target_ids = range(0,15)\n",
    "    target_ids = range(0,2)\n",
    "    font_size = 10\n",
    "    Label=['Benign','Attack']\n",
    "    from matplotlib import pyplot as plt\n",
    "    #plt.figure(figsize=(6, 5))\n",
    "    plt.figure(figsize=(30,10))\n",
    "    #colors = 'r', 'g', 'b', 'c', 'm', 'y', 'k', 'orange', 'purple','dimgray','rosybrown','firebrick','maroon','khaki','indigo'\n",
    "    colors = 'r', 'g'\n",
    "    for i, c, label in zip(target_ids, colors, [_ for _ in target_ids]):\n",
    "        plt.scatter(tsne_resultsRfPred[labelss==i, 0], tsne_resultsRfPred[labelss==i, 1], c=c, label=label,s=1.5)\n",
    "    plt.title(str, fontsize=font_size,loc=\"center\")\n",
    "    plt.xlabel(\"Dimension 1\", fontsize=font_size)\n",
    "    plt.ylabel(\"Dimension 2\", fontsize=font_size)\n",
    "    plt.legend(loc=1,fontsize =font_size,bbox_to_anchor=(1.05, 1,), borderaxespad=-3.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below steps to run Binary mode wihtout sampling(Approach A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step1: load data\n",
    "dataset=data_loading(\"./CSVs/final.csv\")\n",
    "print(\"loading dataset done\")\n",
    "\n",
    "#Step2: plot lables\n",
    "data_plot(dataset)\n",
    "print(\"plot done\")\n",
    "\n",
    "#Step3: preprocess spark dataframe name dataset\n",
    "dataWithFeatures=data_preprocessing(dataset)\n",
    "print(\"preprocess done\")\n",
    "\n",
    "#Step4: create a feature indxer dataframe\n",
    "dataFeature=vectorAssembler(dataWithFeatures)\n",
    "print(\"create a feature indxer done\")\n",
    "\n",
    "#Step5: create train and test data\n",
    "(trainingData, testData)=train_test_data(dataFeature)\n",
    "print(\"create train and test data done\")\n",
    "\n",
    "#Step6: train Binarymode\n",
    "rfModel=train_model(trainingData)\n",
    "print(\"train Binarymode done\")\n",
    "\n",
    "#Step7: output the model results\n",
    "input_array,outputrf=results(rfModel)\n",
    "print(\"output the model results done\")\n",
    "\n",
    "#Step8: visualisation of binary mode\n",
    "resultsTsne=tsneTrain(testData)\n",
    "#flatted to convert from(x,1) to (x,)\n",
    "flattenPredictedLabel=outputrf.round().flatten()\n",
    "flattenTrueLabel=input_array.round().flatten()\n",
    "plot(resultsTsne,flattenPredictedLabel[:80000],\"Original Data Distribution on complete data \")\n",
    "plot(resultsTsne,flattenTrueLabel[:80000],\"Predicted Data Distribution on complete data using RF Classifier \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to run Binary mode with Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Step1: create data with Sampling\n",
    "dataWithSampling=sampling(dataWithFeatures)\n",
    "print(\"Step1: create data with Sampling done\")\n",
    "\n",
    "#Step2: create a feature indxer dataframe\n",
    "dataFeatureWithSampling=vectorAssembler(dataWithSampling)\n",
    "print(\"Step2: create a feature indxer done\")\n",
    "\n",
    "#Step3: create train and test data\n",
    "(trainingDataWithSampling, testDataWithSampling)=train_test_data(dataFeatureWithSampling)\n",
    "print(\"step3: create train and test data done\")\n",
    "\n",
    "#Step4: train Binarymode\n",
    "rfModelWithSampling=train_model(trainingDataWithSampling)\n",
    "print(\"Step4: train Binarymode done\")\n",
    "\n",
    "#Step5: output the model results\n",
    "input_arrayWithSampling,outputrfWithSampling=results(rfModelWithSampling)\n",
    "print(\"Step5: output the model results done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing attack only data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_for_attack_Classification(dataset):\n",
    "    \"\"\"\n",
    "    This function is to filter Benign labels from original dataset and create a pandas df with only attack labels\n",
    "    :param dataset: a spark dataframe\n",
    "    :retrun anomalyDataPandas: a pandas df with only attacks\n",
    "    \"\"\"\n",
    "    featureList=[' Flow Duration', ' Fwd IAT Min', ' Bwd IAT Mean', ' Fwd IAT Mean','Init_Win_bytes_forward',' Subflow Fwd Bytes','Total Length of Fwd Packets',\n",
    "      ' ACK Flag Count', ' Active Min', 'Active Mean',' Flow IAT Std','Init_Win_bytes_forward','Fwd PSH Flags',' SYN Flag Count',\n",
    "      'Fwd Packets/s',' Bwd Packet Length Std','Total Length of Fwd Packets','Init_Win_bytes_forward',' Init_Win_bytes_backward','Total Length of Fwd Packets',\n",
    "      'Total Length of Fwd Packets','Active Mean','Total Length of Fwd Packets',' Fwd Packet Length Mean',' Average Packet Size','Init_Win_bytes_forward', ' Bwd Packets/s', ' PSH Flag Count', ' Flow IAT Min', ' Fwd IAT Min', ' Flow IAT Mean']\n",
    "    uniqueFeature=list(set(featureList))\n",
    "    uniqueFeature.append('Label')\n",
    "    filterData=dataset.select([c for c in dataset.columns if c in uniqueFeature])\n",
    "    attackLabels=[\"DoS Slowhttptest\",'Web Attack � Brute Force','Web Attack � Sql Injection','Web Attack � XSS',\"SSH-Patator\",\"DoS GoldenEye\", \"Heartbleed\", \"DoS Hulk\", \"DoS slowloris\", \"FTP-Patator\", \"Infiltration\",\"Bot\",\"PortScan\",\"DDoS\"]\n",
    "    #to filter column based on column values\n",
    "    anomalyData = filterData.where(col(\"Label\").isin(attackLabels))\n",
    "    anomalyData = anomalyData.filter(anomalyData.Label.isNotNull())\n",
    "    anomalyData = anomalyData.na.fill(0.0)\n",
    "    anomalyData.groupBy('Label').count().collect()\n",
    "    anomalyDataPandas=anomalyData.toPandas()\n",
    "    print(\"Shape of data with only attack records\"+str(anomalyDataPandas.shape))\n",
    "    #anomalyDataPandas.head(5)\n",
    "    return anomalyDataPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combineattacks(x):\n",
    "    \"\"\"\n",
    "    This is to combine all web attcks lables inton one\n",
    "    :param x: pandas df with attacks\n",
    "    :return x: pandas df\n",
    "    \"\"\"\n",
    "    if  x in ['Web Attack � Brute Force','Web Attack � XSS','Web Attack � Sql Injection']:\n",
    "        return \"Web-Attack\"\n",
    "    else : return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_processing_for_Attacks(anomalyDataPandas):\n",
    "    \"\"\"\n",
    "    This method preprocess the pandas df with attacks\n",
    "    :param anomalyDataPandas: pandas df with attacks\n",
    "    :return X,target,data_labels: features, labels, list of labels\n",
    "    \"\"\"\n",
    "    #Filtering features X-label\n",
    "    X=anomalyDataPandas.drop(['Label'],axis=1)\n",
    "    #to convert dtype object to numeric\n",
    "    X.dtypes.eq(object)\n",
    "    c=X.columns[X.dtypes.eq(object)]\n",
    "    X[c]=X[c].apply(pd.to_numeric, errors='coerce', axis=0)\n",
    "    print(\"shape of features in attack data\"+str(X.shape))\n",
    "    #Finding missing values in dataframe \n",
    "    print(\"missing values in dataframe = %g \" %(X.isnull().sum().sum()))\n",
    "    #Filtering Lables Y-label\n",
    "    data_labels =anomalyDataPandas['Label' ]\n",
    "    names = data_labels.unique()\n",
    "    #Encoding labels\n",
    "    target = pd.get_dummies(pd.DataFrame(anomalyDataPandas['Label' ]))\n",
    "    target=target.astype(float)\n",
    "    return X,target,data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def train_regressor_for_Attacks(X,target):\n",
    "    \"\"\"\n",
    "    This method split data into test and train and returns trained model, test data\n",
    "    :param X,target: features, labels\n",
    "    :return regrModel,X_test,y_test: trained model, test data\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.20, random_state=0,stratify=target)\n",
    "    # show the distribution\n",
    "    print('y_train class distribution')\n",
    "    print(y_train.shape)\n",
    "    #instantiating the model\n",
    "    time_start = time.time()\n",
    "    regrModel = RandomForestRegressor(max_depth=50,min_samples_leaf=20,n_estimators=200, random_state=0,criterion='mse',n_jobs=-1)\n",
    "    #Fitting the model on RF Reg\n",
    "    regrModel.fit(X_train,y_train)\n",
    "    print ('model training time elapsed for regression: {} seconds'.format(time.time()-time_start))\n",
    "    return regrModel,X_test,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def results_For_RegrAttacks(regr,y_test):\n",
    "    \"\"\"\n",
    "    This method output model accuracy and its results\n",
    "    \"\"\"\n",
    "    prediction_new=regr.predict(X_test)\n",
    "    print(\"Precision Score for RF model without sampling=%g\"%(precision_score(y_test,prediction_new.round(), average='macro')))\n",
    "    print(\"Recall Score for RF model without sampling=%g\"%(recall_score(y_test,prediction_new.round(), average='macro') )) \n",
    "    print(\"F1 Score for RF model macro=%g\"%(f1_score(y_test, prediction_new.round(), average='macro')))\n",
    "    print(\"without sampling Regressor classification_report\")\n",
    "    print(classification_report(y_test, prediction_new.round(),target_names=y_test.columns))\n",
    "    return prediction_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing attack data with Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "def sampling_with_Encoder(data_labels,X):\n",
    "    \"\"\"\n",
    "    This method encode the labels, then uses Smote for over sampling and fit data on smote\n",
    "    :param data_labels: list of labels\n",
    "    :return X_smote_result, y_smote_result,X_test_smote, y_test_smote: data after using smote\n",
    "    \"\"\"\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(data_labels)\n",
    "    print(\"Lables before encoding: \")\n",
    "    print(le.classes_)\n",
    "    y_withSampling=le.transform(data_labels)\n",
    "    #print(y_withSampling.shape)\n",
    "    print(\"Lables after encoding: \")\n",
    "    print(le.inverse_transform([0,1, 2, 3, 4,5,6,7,8,9,10,11]))\n",
    "    X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X, y_withSampling, test_size=0.20, random_state=0,stratify=y_withSampling)\n",
    "    sm = SMOTE(random_state=42,n_jobs=-1,ratio=0.8)\n",
    "    #ratio = 'auto'\n",
    "    X_smote_result, y_smote_result =sm.fit_sample(X_train_smote, y_train_smote)\n",
    "    from collections import Counter\n",
    "    print(\"Lables values after sampling:\")\n",
    "    print(sorted(Counter(y_smote_result).items()))\n",
    "    return X_smote_result, y_smote_result,X_test_smote, y_test_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regrAttacksResults_withSampling(X_smote_result, y_smote_result,X_test_smote,y_test_smote):\n",
    "    \"\"\"\n",
    "    This method is used to train model on using smote data and print the model reusls\n",
    "    :param X_smote_result, y_smote_result,X_test_smote,y_test_smote: data after using smote\n",
    "    \"\"\"\n",
    "    time_start = time.time()\n",
    "    #instantiating the model\n",
    "    regrSampling = RandomForestRegressor(max_depth=20,min_samples_leaf=10,n_estimators=100, random_state=0,criterion='mse',n_jobs=-1)\n",
    "    #Fitting the model on RF Reg\n",
    "    regrSampling.fit(X_smote_result, y_smote_result)\n",
    "    print ('Training Time elapsed for Smote: {} seconds'.format(time.time()-time_start))\n",
    "    y_predicted_WithSampling=regrSampling.predict(X_test_smote)\n",
    "    print(\"Precision Score for RF model with sampling for regressor=%g\"%\n",
    "      (precision_score(y_test_smote,y_predicted_WithSampling.round(), average='macro')))\n",
    "    print(\"Recall Score for RF model with sampling for regressor=%g\"%\n",
    "      (recall_score(y_test_smote,y_predicted_WithSampling.round(), average='macro')))\n",
    "    print(\"F1  Score for RF model with sampling for regressor=%g\"%(f1_score(y_test_smote, y_predicted_WithSampling.round(), average='macro')))\n",
    "    print(\"with sampling classification_report\")\n",
    "    print(classification_report(y_test_smote, y_predicted_WithSampling.round()))\n",
    "    return regrSampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps to perform Classifaction Attacks (Approach B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset done\n",
      "Shape of data with only attack records(471454, 23)\n",
      "['DDoS' 'PortScan' 'Bot' 'Infiltration' 'Web-Attack' 'FTP-Patator'\n",
      " 'SSH-Patator' 'DoS slowloris' 'DoS Slowhttptest' 'DoS Hulk'\n",
      " 'DoS GoldenEye' 'Heartbleed']\n",
      "shape of features in attack data(471454, 22)\n",
      "missing values in dataframe = 0 \n",
      "y_train class distribution\n",
      "(377163, 12)\n",
      "model training time elapsed for regression: 410.3259468078613 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awanish/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score for RF model without sampling=0.829424\n",
      "Recall Score for RF model without sampling=0.825442\n",
      "F1 Score for RF model macro=0.827414\n",
      "without sampling Regressor classification_report\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "             Label_Bot       0.99      0.99      0.99       393\n",
      "            Label_DDoS       1.00      1.00      1.00      8367\n",
      "   Label_DoS GoldenEye       1.00      1.00      1.00      2059\n",
      "        Label_DoS Hulk       1.00      1.00      1.00     46215\n",
      "Label_DoS Slowhttptest       0.99      0.99      0.99      1100\n",
      "   Label_DoS slowloris       0.99      0.98      0.98      1159\n",
      "     Label_FTP-Patator       1.00      1.00      1.00      1588\n",
      "      Label_Heartbleed       0.00      0.00      0.00         2\n",
      "    Label_Infiltration       0.00      0.00      0.00         7\n",
      "        Label_PortScan       1.00      1.00      1.00     31786\n",
      "     Label_SSH-Patator       1.00      0.99      0.99      1179\n",
      "      Label_Web-Attack       0.99      0.96      0.98       436\n",
      "\n",
      "           avg / total       1.00      1.00      1.00     94291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awanish/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/awanish/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "dataset=data_loading(\"./CSVs/final.csv\")\n",
    "print(\"loading dataset done\")\n",
    "\n",
    "#prepare data for attack calssification\n",
    "anomalyDataPandas=data_for_attack_Classification(dataset=dataset)\n",
    "anomalyDataPandas[\"Label\"] = anomalyDataPandas[\"Label\"].map(lambda x : combineattacks(x))\n",
    "print(\"attack data preparation done\")\n",
    "\n",
    "#preprocessing of attack data\n",
    "X,target,data_labels=data_processing_for_Attacks(anomalyDataPandas)\n",
    "print(\"preprocessing of attack data done\")\n",
    "\n",
    "#RF regressor model tarining and results\n",
    "regrModel,X_test,y_test=train_regressor_for_Attacks(X,target)\n",
    "prediction_regrValue=results_For_RegrAttacks(regrModel,y_test)\n",
    "print(\"RF regressor model tarining and results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving RF regressor model\n",
    "import pickle\n",
    "with open('regrRF.npy','wb') as fout:\n",
    "        pickle.dump(regrModel,fout,pickle.DEFAULT_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running approach B with Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lables before encoding: \n",
      "['Bot' 'DDoS' 'DoS GoldenEye' 'DoS Hulk' 'DoS Slowhttptest'\n",
      " 'DoS slowloris' 'FTP-Patator' 'Heartbleed' 'Infiltration' 'PortScan'\n",
      " 'SSH-Patator' 'Web-Attack']\n",
      "Lables after encoding: \n",
      "['Bot' 'DDoS' 'DoS GoldenEye' 'DoS Hulk' 'DoS Slowhttptest'\n",
      " 'DoS slowloris' 'FTP-Patator' 'Heartbleed' 'Infiltration' 'PortScan'\n",
      " 'SSH-Patator' 'Web-Attack']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awanish/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/awanish/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lables values after sampling:\n",
      "[(0, 147886), (1, 147886), (2, 147886), (3, 184858), (4, 147886), (5, 147886), (6, 147886), (7, 147886), (8, 147886), (9, 147886), (10, 147886), (11, 147886)]\n",
      "Training Time elapsed for Smote: 1089.8444476127625 seconds\n",
      "Precision Score for RF model with sampling for regressor=0.928491\n",
      "Recall Score for RF model with sampling for regressor=0.973131\n",
      "F1  Score for RF model with sampling for regressor=0.926602\n",
      "with sampling classification_report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       393\n",
      "          1       1.00      1.00      1.00      8367\n",
      "          2       0.99      1.00      0.99      2059\n",
      "          3       1.00      1.00      1.00     46215\n",
      "          4       0.99      0.99      0.99      1100\n",
      "          5       0.99      1.00      0.99      1159\n",
      "          6       1.00      1.00      1.00      1588\n",
      "          7       0.20      1.00      0.33         2\n",
      "          8       1.00      0.71      0.83         7\n",
      "          9       1.00      1.00      1.00     31786\n",
      "         10       1.00      0.99      1.00      1179\n",
      "         11       0.99      0.99      0.99       436\n",
      "\n",
      "avg / total       1.00      1.00      1.00     94291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_smote_result, y_smote_result,X_test_smote, y_test_smote=sampling_with_Encoder(data_labels,X)\n",
    "regrSampling=regrAttacksResults_withSampling(X_smote_result, y_smote_result,X_test_smote,y_test_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving RF regressor with Sampling model\n",
    "import pickle\n",
    "with open('regrRFSampling.npy','wb') as fout:\n",
    "        pickle.dump(regrSampling,fout,pickle.DEFAULT_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
